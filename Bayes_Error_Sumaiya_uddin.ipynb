{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055b112b",
   "metadata": {},
   "source": [
    "# dsei2100s23hw1p6-Bayes-Error\n",
    "Classification of 1-D data and Bayes Error\n",
    "\n",
    "## HW1 P6: Classification of 1-D data and Bayes Error\n",
    "\n",
    "Suppose we have two populations of beans. The weights of these beans are normaly distributed, so if $\\mu$ is the mean weight of one type of beans beans and $\\sigma$ is the standard deviation, so that means that the probabilty density is given by \n",
    "    \n",
    "$$p_{\\mu,\\sigma}(x)$ = $\\frac{1}{\\sigma \\sqrt{2\\pi}}$ $e^{-\\frac{1}{2\\sigma}(x-\\mu)^2}$$\n",
    "\n",
    "and then the probabilty of measureing a weight in interval $I=[x_1,x_2]$ of bean of that type is given by\n",
    "\n",
    "$$ P_{\\mu,\\sigma}(I) = \\int^{x_2}_{x_1} p_{\\mu,\\sigma}(x) dx $$\n",
    "\n",
    "The mean weight of bean type A, $\\mu_A$ is 5 grams and the standard deviation, $\\sigma_A$, is 2. The mean weight of bean type B, $mu_B$, is 4 grams and has a standard deviation $\\sigma_B$, of  1.4.\n",
    "\n",
    "Our classifier $C_T(x)$ is determined by a weight threshold $T$:\n",
    "\n",
    "$$f_T(x) = -1 \\mbox{ if } x \\leq T $$\n",
    "\n",
    "$$f_T(x) = 1  \\mbox{ if } T < x  .$$\n",
    "\n",
    "The [*Bayes error*](https://en.wikipedia.org/wiki/Bayes_error_rate) is the probability that we will misclassify. Assume  that there are equally many beans of each type (no prior).\n",
    "\n",
    "### part-A:\n",
    "For a given T write down the theoretical expression (in terms of integrals) for the probability that you will classify a point as bean type A when it is bean type B and similarly that it is bean type B when it is bean type A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6b783",
   "metadata": {},
   "source": [
    "Suppose $C_{T,A}$ is misclassification rates of the classifier $C_T$ for beans of type A and $C_{T,B}$ to be the misclassification rates of the classifier $C_T$ for beans of type B.\n",
    "\n",
    "$C_{T,A}$ can be expressed as the probability that a bean of type A will be classified as Type B, given by:\n",
    "\n",
    "$$C_{T,A} = P_{\\mu_A,\\sigma_A}(x \\leq T) = \\int_{-\\infty}^T p_{\\mu_A,\\sigma_A}(x) dx = \\int_{-\\infty}^T  \\frac{1}{\\sigma_A \\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma_A}(x-\\mu_A)^2} dx$$\n",
    "\n",
    "Same as avobe $C_{T,B}$ can be expressed as the probability that a bean of type B will be classified as type A, given by:\n",
    "\n",
    "$$C_{T,B} = P_{\\mu_B,\\sigma_B}(x > T) = \\int_T^{\\infty} p_{\\mu_B,\\sigma_B}(x) dx = \\int_T^{\\infty} \\frac{1}{\\sigma_B \\sqrt{2\\pi}} e^{-\\frac{1}{2\\sigma_B}(x-\\mu_B)^2} dx$$\n",
    "\n",
    "As both bean types are equally likely, the total misclassification rate is indicated by:\n",
    "\n",
    "$$C_T = \\frac{1}{2}(C_{T,A} + C_{T,B})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0857ed",
   "metadata": {},
   "source": [
    "### Part-B:\n",
    "In python just using numerical functions (you can take 1000 data points from min of weight x=1 to x=8) compute the theorical probailities from part a. Use matplotlib to make a curves showing the probability of classifying something class A ($\\hat{C}=A$ )assuming it is really class B $C=B$, in other words $P(\\hat{C}=A| C=B)$ is the figure y-axis, as a function of $T$, the figure x-axis. Similarly plot $P(\\hat{C}=B| C=A)$ as a fucntion of $T$. Putting these together since $P(A)=P(B)=1/2$, adding the curves and dividing by 2 you get the probability of miss-classification or Bayes error as a function of $T$. Plot that as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aedd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumulative distribution function\n",
    "def C_A(T, mu, sigma):\n",
    "    return norm.cdf(T, mu, sigma)\n",
    "\n",
    "def C_B(T, mu, sigma):\n",
    "    return 1 - norm.cdf(T, mu, sigma)\n",
    "\n",
    "def C_T(T, mu_A, sigma_A, mu_B, sigma_B):\n",
    "    return 0.5 * (C_A(T, mu_A, sigma_A) + C_B(T, mu_B, sigma_B))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
